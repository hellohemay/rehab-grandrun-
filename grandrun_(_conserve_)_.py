# -*- coding: utf-8 -*-
"""Grandrun ( conserve )  .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L7SB5oQkbGSVF0-0I-utcB_e0VTXEzYB
"""

# -*- coding: utf-8 -*-
"""
æ•´åˆç‰ˆï¼šCVA / SCI / TBI è‡ªå‹•ç‰ˆï¼ˆåªåœ¨ã€è‡¨åºŠè©•ä¼°ã€‘ä¾ç‰ˆæœ¬å·®ç•°é¡¯ç¤ºï¼‰
- ç‰ˆæœ¬åˆ¤å®šä¾†è‡ª diagnosis_textï¼ˆSCI / TBI / å…¶ä»–â†’CVAï¼‰
- SCIï¼šé¡¯ç¤º MMT(RUL/RLL/LUL/LLL) + BARTHEL INDEXï¼ˆè‡ª PE æ“·å–ï¼‰
- TBIï¼šé¡¯ç¤º Barthel Indexï¼ˆè‡ª PE æ“·å–ï¼‰
- CVAï¼šé¡¯ç¤º Brunnstrom stageï¼ˆåŸæœ¬è¡Œç‚ºï¼‰
å…¶é¤˜é‚è¼¯ï¼ˆç§»å‹•æ–¹å¼/ååš¥/èªè¨€/èªçŸ¥/è­·ç†/ST/å‡ºé™¢ç›®æ¨™/è¨ˆç•«ä¿®æ­£ï¼‰ç¶­æŒä¸è®Š
"""

import re
from html import unescape

# ============== åŸºæœ¬å·¥å…· ==============
def box(selected: bool) -> str:
    return 'â– ' if selected else 'â–¡'

def safe_lower(s: str | None) -> str:
    return (s or '').lower()

def one_of(text: str, words: list[str]) -> bool:
    tl = safe_lower(text)
    return any(w in tl for w in words)
def infer_hemi_side_from_local(pe_text: str) -> str | None:
    """
    å¾ Local finding æˆ–å…¨æ–‡æ‰¾ 'left/right hemiplegia/hemiparesis' ç­‰å­—æ¨£ï¼Œå›å‚³ 'left' / 'right' / None
    """
    t = safe_lower(pe_text or "")

    # å…ˆæŠ“ Local finding é‚£ä¸€è¡Œï¼ˆè‹¥æœ‰ï¼‰
    m = re.search(r'local\s*finding\s*:\s*(.+)', t, flags=re.I)
    seg = m.group(1) if m else t  # æ²’æŠ“åˆ°å°±ç”¨å…¨æ–‡é™éšåˆ¤è®€

    # å³å´
    right_pats = [
        r'\bright[^a-z]{0,3}(hemiplegia|hemiparesis)\b',
        r'\brt\.?\b[^.\n]{0,10}(hemiplegia|hemiparesis)\b',
    ]
    for p in right_pats:
        if re.search(p, seg): return 'right'

    # å·¦å´
    left_pats = [
        r'\bleft[^a-z]{0,3}(hemiplegia|hemiparesis)\b',
        r'\blt\.?\b[^.\n]{0,10}(hemiplegia|hemiparesis)\b',
    ]
    for p in left_pats:
        if re.search(p, seg): return 'left'

    return None

# ===== è£œé½Šï¼šå…±ç”¨å°å·¥å…· =====
def _token_min_value(tok: str | None) -> float:
    """
    æŠŠ '4', '4+', '3-4', 'NT' é€™é¡å­—ä¸²è½‰æˆç”¨ä¾†æ¯”è¼ƒçš„ã€Œæœ€ä½æ•¸å€¼ã€ã€‚
    ç”¨æ–¼ä¼°ç®— MMT/MP æ˜¯å¦ < 3ã€‚
    """
    if not tok:
        return float('inf')
    s = str(tok).strip().upper()
    if s == 'NT':
        return float('inf')
    # æŠ“å‡ºæ‰€æœ‰ 0-5 çš„æ•¸å­—ï¼Œå–æœ€å°
    nums = re.findall(r'[0-5]', s)
    if not nums:
        return float('inf')
    return float(min(int(n) for n in nums))

def build_treatment_block(flags: dict) -> str:
    """
    ä¾ parse_treatments_from_html() + apply_st_from_assessment() çš„ flags
    è¼¸å‡ºã€æ²»ç™‚è¨ˆç•«ã€‘å€å¡Šã€‚
    """
    def line_from(cat: str, items: list[str]) -> str:
        return cat + ": " + " ".join(f"{box(flags.get(cat, {}).get(it, False))}{it}" for it in items)

    pt_items = ['PROM', 'å‚¾æ–œå°', 'ä¿ƒé€²', 'é‹å‹•', 'è½‰ä½', 'è‚ŒåŠ›', 'è€åŠ›', 'è¡Œèµ°', 'æ­¥æ…‹', 'ç†±æ•·', 'é›»ç™‚']
    ot_items = ['PROM', 'å§¿æ…‹', 'è‚ŒåŠ›', 'åç«™å¹³è¡¡', 'æ—¥å¸¸ç”Ÿæ´»', 'æŒæŒ‡åŠŸèƒ½', 'å”èª¿', 'ä¸Šä¸‹è‚¢åŠŸèƒ½', 'é‹å‹•æ„Ÿè¦º']
    st_items = ['å¤±èªç—‡', 'ååš¥å›°é›£', 'æ§‹éŸ³å›°é›£']
    psy_items = ['æˆäººæ”¯æŒ', 'è¡Œç‚ºæ²»ç™‚è¨ˆç•«', 'æˆäººå¿ƒç†ç”Ÿç†', 'å¿ƒç†æ¸¬è©¦', 'äººæ ¼ç‰¹è³ª']
    nurse_items = ['è‡ªæˆ‘ç…§é¡§èƒ½åŠ›', 'æ¥å—è¡›æ•™èƒ½åŠ›', 'ç”¨è—¥æŒ‡å°', 'è·Œå€’å±éšªå› å­', 'èº«é«”æ´»å‹•åŠŸèƒ½']

    lines = ["ã€æ²»ç™‚è¨ˆç•«ã€‘"]
    lines.append(line_from('PT', pt_items))
    lines.append(line_from('OT', ot_items))
    lines.append(line_from('ST', st_items))
    lines.append(line_from('PSY', psy_items))
    lines.append(line_from('NURSE', nurse_items))
    return "\n".join(lines)

def build_discharge_goals(goals: dict) -> str:
    """
    æŠŠ infer_discharge_goals_from_all() çš„çµæœè½‰æˆå‡ºé™¢ç›®æ¨™å€å¡Šã€‚
    """
    order = [
        "è‡ªè¡Œç¿»èº«", "åå§¿å¹³è¡¡", "è‡ªè¡Œè½‰ä½", "ç«™ç«‹",
        "è‡ªè¡Œæ“æ§è¼ªæ¤…æ´»å‹•", "å”åŠ©æŒè¼”åŠ©å™¨è¡Œèµ°", "æŒè¼”åŠ©å™¨ç¨ç«‹è¡Œèµ°",
    ]
    lines = ["ã€å‡ºé™¢ç›®æ¨™ã€‘"]
    lines.append(" ".join(f"{box(bool(goals.get(k)))}{k}" for k in order))
    return "\n".join(lines)



# ============== ç‰ˆæœ¬åˆ¤å®šï¼ˆè¨ºæ–·æ–‡å­—ï¼‰ ==============
def detect_case_type(diagnosis_text: str) -> str:
    d = safe_lower(diagnosis_text)
    if re.search(r'\b(sci|spinal\s*cord\s*injury)\b', d):
        return 'SCI'
    if re.search(r'\b(tbi|traumatic\s*brain\s*injury|head\s*injury)\b', d):
        return 'TBI'
    # æ³›ç”¨é»˜èª CVAï¼ˆstroke/ICH/infarct/embolism ç­‰ï¼‰
    return 'CVA'

# ============== åç™±å´ï¼ˆè¨ºæ–· / MP / Brunnstromï¼‰ ==============
def infer_hemiparesis_side(text: str) -> str | None:
    if not text: return None
    t = text.lower()
    right_patterns = [
        r'\bright(?:[-\s]*sided)?\s*(?:hemi(?:paresis|plegia)|weakness)\b',
        r'(?:hemi(?:paresis|plegia)|weakness)\b[^.\n]*\bright(?:[-\s]*side)?\b',
        r'\brt?\.?\s*(?:hemi(?:paresis|plegia)|weakness)\b',
        r'\br(?:ight)?\s*side\b[^.\n]*\bhemi(?:paresis|plegia)\b',
        r'\brhp\b',
    ]
    left_patterns = [
        r'\bleft(?:[-\s]*sided)?\s*(?:hemi(?:paresis|plegia)|weakness)\b',
        r'(?:hemi(?:paresis|plegia)|weakness)\b[^.\n]*\bleft(?:[-\s]*side)?\b',
        r'\blt?\.?\s*(?:hemi(?:paresis|plegia)|weakness)\b',
        r'\bl(?:eft)?\s*side\b[^.\n]*\bhemi(?:paresis|plegia)\b',
        r'\blhp\b',
    ]
    for p in right_patterns:
        if re.search(p, t): return 'right'
    for p in left_patterns:
        if re.search(p, t): return 'left'
    return None

def _mp_to_float(mp_str: str) -> float:
    mp_str = (mp_str or "").strip()
    m = re.match(r'([0-5])([+-]?)', mp_str)
    if not m: return float('nan')
    base = float(m.group(1)); suf = m.group(2)
    if suf == '+': base += 0.33
    elif suf == '-': base -= 0.33
    return base

def infer_hemiparesis_side_from_mp(pe_text: str) -> str | None:
    if not pe_text: return None
    t = pe_text
    candidates = []
    r1 = re.findall(r'\bR(?:ight)?[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?)', t, flags=re.I)
    l1 = re.findall(r'\bL(?:eft)?[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?)',  t, flags=re.I)
    if r1: candidates.append(('right', _mp_to_float(r1[-1])))
    if l1: candidates.append(('left',  _mp_to_float(l1[-1])))
    r2 = re.findall(r'MP\s*\(\s*R(?:ight)?\s*\)\s*[:ï¼š]?\s*([0-5][+-]?)', t, flags=re.I)
    l2 = re.findall(r'MP\s*\(\s*L(?:eft)?\s*\)\s*[:ï¼š]?\s*([0-5][+-]?)',  t, flags=re.I)
    if r2: candidates.append(('right', _mp_to_float(r2[-1])))
    if l2: candidates.append(('left',  _mp_to_float(l2[-1])))
    parts = re.findall(r'\b(R|L)(?:UE|LE)\b[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?)', t, flags=re.I)
    if parts:
        r_vals, l_vals = [], []
        for side, mp in parts:
            (r_vals if side.upper()=='R' else l_vals).append(_mp_to_float(mp))
        if r_vals: candidates.append(('right', sum(r_vals)/len(r_vals)))
        if l_vals: candidates.append(('left',  sum(l_vals)/len(l_vals)))
    if not candidates: return None
    r_val = next((v for s, v in candidates if s=='right' and v==v), None)
    l_val = next((v for s, v in candidates if s=='left'  and v==v), None)
    if r_val is not None and l_val is not None:
        if r_val + 0.5 <= l_val: return 'right'
        if l_val + 0.5 <= r_val: return 'left'
    return None

def parse_mp_from_pe(pe_text: str) -> dict:
    t = pe_text or ""
    vals_R, vals_L = [], []
    r_pat = re.findall(r'\bR(?:ight)?[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?)', t, flags=re.I)
    l_pat = re.findall(r'\bL(?:eft)?[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?)',  t, flags=re.I)
    r2 = re.findall(r'MP\s*\(\s*R(?:ight)?\s*\)\s*[:ï¼š]?\s*([0-5][+-]?)', t, flags=re.I)
    l2 = re.findall(r'MP\s*\(\s*L(?:eft)?\s*\)\s*[:ï¼š]?\s*([0-5][+-]?)',  t, flags=re.I)
    parts = re.findall(r'\b(R|L)(?:UE|LE)\b[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?)', t, flags=re.I)
    vals_R += [_mp_to_float(x) for x in r_pat+r2]
    vals_L += [_mp_to_float(x) for x in l_pat+l2]
    for side, mp in parts:
        (vals_R if side.upper()=='R' else vals_L).append(_mp_to_float(mp))
    def _avg(lst):
        lst = [x for x in lst if x==x]
        return sum(lst)/len(lst) if lst else float('nan')
    R = _avg(vals_R); L = _avg(vals_L)
    if (R==R) and (L==L): ALL = (R+L)/2
    elif (R==R): ALL = R
    elif (L==L): ALL = L
    else: ALL = float('nan')
    return {'R':R,'L':L,'all':ALL}

# ============== å¤±èª/ååš¥/æ°£åˆ‡åµæ¸¬ ==============
def infer_aphasia_types(diag_text: str, pe_text: str) -> tuple[bool, bool]:
    d = safe_lower(diag_text); p = safe_lower(pe_text)
    expr_keys = [r'\bbroca\b', r'\bmotor\b', r'\bexpressive\b', r'\btranscortical\s*motor\b', r'\btcma\b']
    recep_keys = [r'\bwernicke\b', r'\bsensory\b', r'\breceptive\b', r'\btranscortical\s*sensory\b', r'\btcsa\b']
    global_keys = [r'\bglobal\b']
    expr = any(re.search(k, d) for k in expr_keys)
    recep = any(re.search(k, d) for k in recep_keys)
    if any(re.search(k, d) for k in global_keys): expr, recep = True, True
    if not (expr or recep):
        def get_field_val(field: str) -> str | None:
            m = re.search(rf'{field}\s*:\s*([A-Za-z\-]+)', p); return m.group(1).lower() if m else None
        def is_imp(val: str | None) -> bool:
            return bool(val) and any(x in val for x in ['impaired','poor','decreased','abnormal','non-fluent','nonfluent','aphasia'])
        if is_imp(get_field_val('fluency')): expr = True
        if is_imp(get_field_val('comprehension')): recep = True
    if not (expr or recep):
        m = re.search(r'aphasia\s*\(\s*([+-])\s*\)', p)
        if m and m.group(1)=='+': expr = True
    return expr, recep

def infer_speech_swallow_trach(diagnosis_text: str, pe_text: str):
    d = safe_lower(diagnosis_text or "")
    p = safe_lower(pe_text or "")

    # --- æ§‹éŸ³ ---
    if re.search(r'dysarthria\s*\(\s*-\s*\)', d+'\n'+p):
        dysarthria = False
    elif re.search(r'dysarthria\s*\(\s*\+\s*\)', d+'\n'+p):
        dysarthria = True
    else:
        # ç„¡ (+/-) æ™‚æ‰æŠŠå­¤ç«‹çš„ dysarthria è¦–ç‚ºæœ‰
        dysarthria = bool(re.search(r'\bdysarthria\b', d+'\n'+p))

    # --- NG / æ°£åˆ‡ï¼ˆå¾ Local finding æœ€æœ«æ®µåˆ¤ï¼‰---
    lines = [ln.strip().lower() for ln in (pe_text or "").splitlines() if ln.strip()]
    ng_plus = False
    trach_plus = False
    for ln in reversed(lines):
        if ln.startswith('local finding'):
            if re.search(r'ng[^a-z0-9]*\+', ln):     ng_plus = True
            if re.search(r'(tracheostomy|tr\.)[^a-z0-9]*\+', ln): trach_plus = True
            break
    # æ–‡å…§å¦å¯« tracheostomy(+) ä¹Ÿç®—
    trach_plus = trach_plus or bool(re.search(r'\btracheostomy\b.*\(\+\)', d+'\n'+p))

    # --- ååš¥ï¼ˆåªåœ¨ä»¥ä¸‹æƒ…æ³æ‰ç®—æœ‰ï¼‰---
    # 1) è¨ºæ–·æ–‡å­—æœ‰ dysphagiaï¼ˆä¸”ä¸æ˜¯ no/without/(-)ï¼‰
    dx_has_dysphagia = bool(
        re.search(r'\bdysphagia\b', d) and
        not re.search(r'(no|without)\s+dysphagia|dysphagia\s*\(\s*-\s*\)', d)
    )
    # 2) PE æ˜å¯« (+) æ‰ç®—ï¼›(-) ä¸€å¾‹ç•¶ä½œæ²’æœ‰ï¼›æ²’æœ‰ (+/-) ä¸ç•¶ä½œæœ‰
    pe_has_plus = bool(re.search(r'dysphagia\s*\(\s*\+\s*\)', p))
    pe_has_minus = bool(re.search(r'dysphagia\s*\(\s*-\s*\)', p))

    dysphagia_any = False
    if ng_plus:
        dysphagia_any = True
    elif dx_has_dysphagia:
        dysphagia_any = True
    elif pe_has_plus:
        dysphagia_any = True
    elif pe_has_minus:
        dysphagia_any = False
    else:
        dysphagia_any = False  # æ²’å¯« (+/-) ä¸”è¨ºæ–·æ²’æ â†’ ä¸ç•¶ä½œæœ‰

    return dysarthria, dysphagia_any, trach_plus, ng_plus


# ============== Functional status è§£æï¼ˆç§»ä½/ç§»å‹•/è¡Œèµ°ï¼‰ ==============
def parse_functional_components(pe_text: str) -> dict:
    """
    æ‹†å‡ºå„é …åŠŸèƒ½ç­‰ç´šï¼šrolling / sit_up / sit_bal / transfer / stand_up / stand_bal / walk
    å›å‚³å€¼çš†æ˜¯ 'poor' / 'fair' / 'fair~good' / 'good' / None
    """
    t = safe_lower(pe_text or "")

    def pick_level(pattern: str) -> str | None:
        m = re.search(rf'{pattern}[^.\n]{{0,40}}(poor|fair~good|fair|good)', t)
        return m.group(1) if m else None

    return {
        # ç¿»èº«
        'rolling':   pick_level(r'\brolling\b'),
        # åèµ·ï¼ˆæ’é™¤ã€Œsitting balanceã€ï¼‰
        'sit_up':    pick_level(r'\bsit(?:ting)?(?:\s*up)?\b(?![^.\n]*balance)'),
        # åå§¿å¹³è¡¡
        'sit_bal':   pick_level(r'\bsitting\s*balance\b'),
        # è½‰ä½
        'transfer':  pick_level(r'\btransfer\b'),
        # ç«™èµ·ï¼ˆæ’é™¤ã€Œstanding balanceã€ï¼‰
        'stand_up':  pick_level(r'\bstanding(?:\s*up)?\b(?![^.\n]*balance)'),
        # ç«™ç«‹å¹³è¡¡
        'stand_bal': pick_level(r'\bstanding\s*balance\b'),
        # è¡Œèµ°/æ­¥æ…‹ï¼ˆæœ‰äº›æœƒæ¨™ gait/ambulationï¼‰
        'walk':      pick_level(r'\b(ambulation|walking|gait|walk)\b'),
    }

def infer_mobility_from_function(pe_text: str) -> str:
    """
    ç§»å‹•æ–¹å¼ (Mobility) è¦å‰‡ï¼š
    - å®Œå…¨æ²’æåˆ°ä»»ä½•åŠŸèƒ½/æ­¥æ…‹ â†’ å›å‚³ç©ºå­—ä¸²ï¼ˆä¸å‹¾ï¼‰
    - è‹¥ rolling èˆ‡ sit_up éƒ½æ˜¯ poor â†’ Bed ridden
    - è‹¥ sit_up ç‚º poor ä½† sitting balance å·²ç¶“ â‰¥ fair â†’ W/C care
    - è‹¥ä¸‹åˆ— 5 é …ä¸­ï¼ˆsit_up, transfer, stand_up, sit_bal, stand_balï¼‰è‡³å°‘æœ‰ã€Œ2 é …ã€ç­‰ç´š â‰¥ fair â†’ W/C activity
    - è‹¥æ­¥æ…‹/èµ°è·¯è³‡è¨Šé¡¯ç¤ºå¯è¡Œèµ°ï¼š
        * æœ‰å¯« walkerï¼ˆwalk with/using walkerï¼‰â†’ walker
        * æœ‰å¯« free ambulation æˆ– walk independently/without walker â†’ Free ambulation
        * è‹¥åƒ…æœ‰ walk/gait ç­‰ç´š 'good' æˆ– 'fair~good' â†’ Free ambulation
        * è‹¥ walk/gait ç­‰ç´š 'poor' â†’ walker
    - è‹¥åŒæ™‚å‘½ä¸­ã€Œæ­¥æ…‹å¯èµ°ã€èˆ‡å‰è¿°æ¢ä»¶ï¼Œæ­¥æ…‹åˆ¤è®€å„ªå…ˆï¼ˆwalker / Free ambulation æœƒè¦†è“‹å‰é¢çš„ W/C*ï¼‰
    """
    comp = parse_functional_components(pe_text)
    has_any = any(comp.values()) or bool(re.search(r'\b(ambulation|walking|gait|walk)\b', safe_lower(pe_text or "")))
    if not has_any:
        return ""  # å®Œå…¨æ²’è³‡è¨Š â†’ ç©ºç™½

    # 1) æœ€é‡ï¼šç¿»èº«+åèµ·éƒ½ poor â†’ Bed ridden
    if (comp.get('rolling') == 'poor') and (comp.get('sit_up') == 'poor'):
        mobility = 'Bed ridden'
    else:
        # 2) åèµ· poor ä½†åå§¿å¹³è¡¡ >= fair â†’ W/C care
        if comp.get('sit_up') == 'poor' and comp.get('sit_bal') in ('fair', 'fair~good', 'good'):
            mobility = 'W/C care'
        else:
            # 3) åœ¨ä¸‹åˆ— 5 é …ä¸­ï¼Œè‡³å°‘ 2 é …é”åˆ° >= fair â†’ W/C activity
            bucket = [comp.get('sit_up'), comp.get('transfer'), comp.get('stand_up'), comp.get('sit_bal'), comp.get('stand_bal')]
            at_least_fair = sum(1 for x in bucket if x in ('fair', 'fair~good', 'good'))
            mobility = 'W/C activity' if at_least_fair >= 2 else 'W/C care'

    # 4) ä¾æ­¥æ…‹/èµ°è·¯è¦†è“‹
    txt = safe_lower(pe_text or "")
    # 4a) æ–‡å­—åˆ¤è®€ï¼ˆè‡ªç”±è¡Œèµ° / éœ€è¦åŠ©è¡Œå™¨ï¼‰
    free_patterns = [
        r'\bfree\s*ambulation\b',
        r'\bwalk(?:ing)?\s+(independent|independently)\b',
        r'\bwalk(?:ing)?\s+without\s+(a\s*)?(walker|aid|assistive\s*device)\b',
    ]
    walker_patterns = [
        r'\bwalk(?:ing)?\s+(with|using)\s+(a\s*)?walker\b',
        r'\bwalker\b',
    ]
    if any(re.search(p, txt) for p in walker_patterns):
        return 'walker'
    if any(re.search(p, txt) for p in free_patterns):
        return 'Free ambulation'

    # 4b) ä»¥ walk/gait çš„ç­‰ç´šæ¨è«–
    walk_level = comp.get('walk')
    if walk_level in ('good', 'fair~good'):
        return 'Free ambulation'
    if walk_level == 'poor':
        return 'walker'

    return mobility

def infer_transfer_from_function(pe_text: str) -> str:
    """
    è½‰ä½èƒ½åŠ›ï¼šç›´æ¥è®€ functional status çš„ transfer ç­‰ç´šã€‚
    æ²’å¯«å°±å›å‚³ç©ºå­—ä¸²ï¼ˆä¸å‹¾ï¼‰ã€‚
    """
    level = parse_functional_components(pe_text).get('transfer')
    if level == 'good': return 'Good'
    if level == 'fair~good': return 'Fair~good'
    if level == 'fair': return 'Fair'
    if level == 'poor': return 'Poor'
    return ""


# ============== Brunnstrom / MAS ==============
def parse_brunnstrom_block(pe_text: str) -> tuple[str, str, str, str]:
    pe = pe_text or ''
    mL = re.search(r'left\s*limbs\s*:\s*([IVXivx\-\s/]+)', pe, re.I)
    mR = re.search(r'right\s*limbs\s*:\s*([IVXivx\-\s/]+)', pe, re.I)
    side, parts = 'Right', None
    if mR: side, parts = 'Right', mR.group(1)
    if mL: side, parts = 'Left',  mL.group(1)
    up = ud = ll = 'NA'
    if parts:
        seg = [x.strip() for x in parts.split('/') if x.strip()]
        if len(seg) == 3: up, ud, ll = seg
    return side, up, ud, ll

def default_mas():
    return ('0/0/0', '0/0', '0/0/0', '0/0')

# ============== èªçŸ¥éšœç¤™ï¼ˆä»¥ Comprehension ç‚ºä¸»ï¼‰ ==============
def infer_cognition_level(pe_text: str) -> str:
    p = safe_lower(pe_text or "")
    if re.search(r'comprehension\s*:\s*(impaired|poor|decreased|abnormal)', p):
        return 'å·®'
    if re.search(r'comprehension\s*:\s*(fair|fair~good)', p):
        return 'å°šå¯'
    if re.search(r'cognition[^:\n]*\b(poor|impaired|decreased|abnormal)\b', p):
        return 'å·®'
    if re.search(r'cognition[^:\n]*\bfair\b', p):
        return 'å°šå¯'
    return 'è‰¯'

# ============== Local finding ç®¡è·¯ï¼ˆNG/Foley/Tr.ï¼‰ ==============
def parse_local_finding_tubes(pe_text: str) -> tuple[bool,bool,bool]:
    lines = [ln.strip().lower() for ln in (pe_text or "").splitlines() if ln.strip()]
    ng = foley = tr = False
    for ln in reversed(lines):
        if ln.startswith('local finding'):
            if re.search(r'ng[^a-z0-9]*\+', ln):     ng = True
            if re.search(r'foley[^a-z0-9]*\+', ln):  foley = True
            if re.search(r'(tracheostomy|tr\.)[^a-z0-9]*\+', ln): tr = True
            break
    return ng, foley, tr

# ============== ST è‡ªå‹•è¦†è“‹ï¼ˆç”±è‡¨åºŠè©•ä¼°ï¼‰ ==============
def apply_st_from_assessment(flags: dict, diagnosis_text: str, pe_text: str) -> dict:
    expr, recep = infer_aphasia_types(diagnosis_text, pe_text)
    dysarthria, dysphagia_any, _, _ = infer_speech_swallow_trach(diagnosis_text, pe_text)
    has_aphasia = bool(expr or recep)
    flags.setdefault('ST', {'å¤±èªç—‡': False, 'ååš¥å›°é›£': False, 'æ§‹éŸ³å›°é›£': False})
    flags['ST']['å¤±èªç—‡']   = has_aphasia
    flags['ST']['ååš¥å›°é›£'] = dysphagia_any
    flags['ST']['æ§‹éŸ³å›°é›£'] = bool(dysarthria)
    return flags


# ============== è§£æ HTML â†’ æ²»ç™‚è¨ˆç•«ï¼ˆè­·ç†å…¨å‹¾ï¼›ä¸è‡ªå‹•å‹¾ PTé‹å‹•/è‚ŒåŠ›/OTä¸Šä¸‹è‚¢åŠŸèƒ½/è‚ŒåŠ›ï¼‰ ==============
def parse_treatments_from_html(html_text: str) -> dict:
    txt = unescape(re.sub(r'\s+', ' ', html_text or "")).lower()

    def has(*keys):
        return any(k.lower() in txt for k in keys)

    result = {
        'PT': {'PROM': False, 'å‚¾æ–œå°': False, 'ä¿ƒé€²': False, 'é‹å‹•': False, 'è½‰ä½': False, 'è‚ŒåŠ›': False,
               'è€åŠ›': False, 'è¡Œèµ°': False, 'æ­¥æ…‹': False, 'ç†±æ•·': False, 'é›»ç™‚': False},
        'OT': {'PROM': False, 'å§¿æ…‹': False, 'è‚ŒåŠ›': False, 'åç«™å¹³è¡¡': False, 'æ—¥å¸¸ç”Ÿæ´»': False,
               'æŒæŒ‡åŠŸèƒ½': False, 'å”èª¿': False, 'ä¸Šä¸‹è‚¢åŠŸèƒ½': False, 'é‹å‹•æ„Ÿè¦º': False},
        'ST': {'å¤±èªç—‡': False, 'ååš¥å›°é›£': False, 'æ§‹éŸ³å›°é›£': False},
        'PSY': {'æˆäººæ”¯æŒ': False, 'è¡Œç‚ºæ²»ç™‚è¨ˆç•«': False, 'æˆäººå¿ƒç†ç”Ÿç†': False, 'å¿ƒç†æ¸¬è©¦': False, 'äººæ ¼ç‰¹è³ª': False},
        'NURSE': {'è‡ªæˆ‘ç…§é¡§èƒ½åŠ›': True, 'æ¥å—è¡›æ•™èƒ½åŠ›': True, 'ç”¨è—¥æŒ‡å°': True, 'è·Œå€’å±éšªå› å­': True, 'èº«é«”æ´»å‹•åŠŸèƒ½': True}
    }

    # ---------- PT å°æ‡‰ ----------
    # PROM
    if has('ptm5', 'passive r.o.m', 'passive rom', 'è¢«å‹•æ€§é—œç¯€é‹å‹•'):
        result['PT']['PROM'] = True
    # å‚¾æ–œå°
    if has('ptm8', 'tilting table'):
        result['PT']['å‚¾æ–œå°'] = True
    # ä¿ƒé€²ï¼ˆç¥ç¶“ä¿ƒé€²æŠ€å·§ï¼‰
    if has('ptc1', 'facilitation techniques', 'ä¿ƒé€²æŠ€è¡“', 'å§¿å‹¢è¨“ç·´', 'posture training', 'ptm13'):
        result['PT']['ä¿ƒé€²'] = True
    # é‹å‹•ï¼ˆä¸€èˆ¬æ²»ç™‚æ€§é‹å‹•/ä¼¸å±•ï¼‰
    if has('ptm7', 'therapeutic ex', 'ptm6', 'stretching'):
        result['PT']['é‹å‹•'] = True
    # è½‰ä½ï¼ˆPT æ¸…å–®æ²’æœ‰æ˜ç¢º transfer é …ï¼›ä¸è‡ªå‹•å‹¾ï¼‰
    # è‚ŒåŠ›
    if has('ptm9', 'strengthening'):
        result['PT']['è‚ŒåŠ›'] = True
    # è€åŠ›
    if has('ptm10', 'endurance'):
        result['PT']['è€åŠ›'] = True
    # è¡Œèµ° / æ­¥æ…‹
    if has('ptc6', 'ambulation training', 'è¡Œèµ°è¨“ç·´'):
        result['PT']['è¡Œèµ°'] = True
        result['PT']['æ­¥æ…‹'] = True
    # ç†±æ•·ï¼ˆå« hot/cold packã€paraffin ç­‰ç†±ç™‚ï¼‰
    if has('pts2', 'hot\\cold pack', 'hot cold pack', 'ç†±æ•·') or has('pts4', 'paraffin'):
        result['PT']['ç†±æ•·'] = True
    # é›»ç™‚ï¼ˆtensï¼å¹²æ“¾æ³¢ï¼è‚Œé›»åˆºæ¿€ï¼é›·å°„ç­‰çš†ç®—ï¼‰
    if has('pts8', 'interferential') or has('pts9', 'tens') or has('ptm1', 'muscle stimulation') \
       or has('pts11', 'low power laser') or has('pts10', 'high frequency discharge'):
        result['PT']['é›»ç™‚'] = True
    # å…¶é¤˜ç‰©ç†å› å­æ²»ç™‚ï¼ˆè¶…éŸ³æ³¢ã€çŸ­æ³¢ã€å¾®æ³¢â€¦ï¼‰ä¸å½±éŸ¿ä¸Šè¿° 11 å€‹æ¬„ä½ï¼Œå°±ä¸é¡å¤–å°æ˜ 

    # ---------- OT å°æ‡‰ ----------
    # PROM
    if has('ot2', 'è¢«å‹•æ€§é—œç¯€è¨“ç·´', 'passive'):
        result['OT']['PROM'] = True
    # å§¿æ…‹
    if has('ot1', 'posture training', 'å§¿æ…‹è¨“ç·´'):
        result['OT']['å§¿æ…‹'] = True
    # è‚ŒåŠ›
    if has('ot6', 'muscle strenght', 'muscle strength'):
        result['OT']['è‚ŒåŠ›'] = True
    # åç«™å¹³è¡¡
    if has('ot3', 'åç«™å¹³è¡¡', 'sitting balance'):
        result['OT']['åç«™å¹³è¡¡'] = True
    # æ—¥å¸¸ç”Ÿæ´»
    if has('ot5', 'adl training', 'æ—¥å¸¸ç”Ÿæ´»'):
        result['OT']['æ—¥å¸¸ç”Ÿæ´»'] = True
    # æŒæŒ‡åŠŸèƒ½
    if has('ot10', 'hand on foot function', 'æŒæŒ‡åŠŸèƒ½'):
        result['OT']['æŒæŒ‡åŠŸèƒ½'] = True
    # å”èª¿
    if has('ot11', 'coordination', 'å”èª¿è¨“ç·´'):
        result['OT']['å”èª¿'] = True
    # ä¸Šä¸‹è‚¢åŠŸèƒ½
    if has('ot8', 'u/e or l/e function training', 'ä¸Šè‚¢(ä¸‹è‚¢)åŠŸèƒ½è¨“ç·´', 'ä¸Šä¸‹è‚¢åŠŸèƒ½'):
        result['OT']['ä¸Šä¸‹è‚¢åŠŸèƒ½'] = True
    # é‹å‹•æ„Ÿè¦ºï¼ˆæ„Ÿè¦ºçµ±åˆ/é‹å‹•çŸ¥è¦ºï¼‰
    if has('ot7', 'motion sensory', 'é‹å‹•çŸ¥è¦º', 'sensory'):
        result['OT']['é‹å‹•æ„Ÿè¦º'] = True

    # ---------- ST/PSYï¼šä¿ç•™ä½ åŸæœ¬è¦å‰‡ ----------
    if 'ååš¥' in txt or 'oral tx' in txt: result['ST']['ååš¥å›°é›£'] = True
    if 'æ§‹éŸ³' in txt or 'dysarthria' in txt: result['ST']['æ§‹éŸ³å›°é›£'] = True
    if any(k in txt for k in ['èªè¨€æ²»ç™‚', 'auditory comprehension', 'verbal production']): result['ST']['å¤±èªç—‡'] = True

    if 'è¡Œç‚ºæ²»ç™‚è¨ˆç•«' in txt: result['PSY']['è¡Œç‚ºæ²»ç™‚è¨ˆç•«'] = True
    if any(k in txt for k in ['å¿ƒç†æ¸¬æª¢', 'å¿ƒç†æ¸¬è©¦', 'é›»è…¦åŒ–ç¥ç¶“å¿ƒç†æ¸¬é©—']): result['PSY']['å¿ƒç†æ¸¬è©¦'] = True
    if 'äººæ ¼ç‰¹è³ª' in txt: result['PSY']['äººæ ¼ç‰¹è³ª'] = True
    if any(k in txt for k in ['ç”Ÿç†å¿ƒç†åŠŸèƒ½', 'æˆäºº']):
        result['PSY']['æˆäººå¿ƒç†ç”Ÿç†'] = True
        result['PSY']['æˆäººæ”¯æŒ'] = True

    return result


# ============== Barthel Index å€å¡Šæ“·å–ï¼ˆåŸæ–‡å¸¶å‡ºï¼‰ ==============
def extract_barthel_block(pe_text: str) -> str | None:
    if not pe_text: return None
    lines = pe_text.splitlines()
    start_idx = None
    for i, ln in enumerate(lines):
        if re.search(r'^\s*barthel\s*index\s*$', ln, flags=re.I) or re.search(r'^\s*barthel\s*index\b', ln, flags=re.I):
            start_idx = i
            break
    if start_idx is None:
        # ä¹Ÿæ”¯æ´å…¨å¤§å¯« BARTHEL INDEX
        for i, ln in enumerate(lines):
            if re.search(r'^\s*BARTHEL\s*INDEX\s*$', ln):
                start_idx = i
                break
    if start_idx is None:
        return None
    # å¾€ä¸‹æ”¶é›†åˆ°ç©ºè¡Œï¼åˆ†éš”ç·šï¼ä¸‹ä¸€å€‹å¤§æ®µæ¨™é¡Œ
    buff = []
    for ln in lines[start_idx:]:
        if not ln.strip():
            if buff: break
        if re.match(r'={3,}', ln): break
        if re.match(r'^\s*(Local finding|Functional status|COORDINATION|OTHER NEUROLOGICAL|SENSORY FUNCTION)\b', ln, flags=re.I):
            break
        buff.append(ln.rstrip())
    return '\n'.join(buff).strip() if buff else None

# ============== SCI å°ˆç”¨ï¼šå¾ MP è¡¨æ ¼ä¼° MMTï¼ˆRUL/RLL/LUL/LLLï¼‰ ==============
def _pick_min_score_token(tokens: list[str]) -> str | None:
    """åœ¨å¤šå€‹ '0-5(+/-)'ã€'3-4'ã€'NT' æ¨™è¨˜ä¸­ï¼Œå›å‚³**æœ€ä½**é‚£ä¸€å€‹ï¼ˆä¿ç•™åŸå­—ä¸²ï¼‰ã€‚"""
    def tok_min_val(tok: str) -> float:
        if not tok: return float('inf')
        t = tok.strip().upper()
        if t == 'NT': return float('inf')
        # '3-4' å– 3ï¼›'4-'ã€'3+' éƒ½ä»¥æ•¸å­—æœ¬é«”è¨ˆç®—
        nums = re.findall(r'[0-5]', t)
        return min(float(n) for n in nums) if nums else float('inf')
    if not tokens: return None
    return sorted(tokens, key=tok_min_val)[0]

def parse_mmt_ul_ll_from_pe(pe_text: str) -> dict:
    """
    å„ªå…ˆè§£æ M.P.(0-5) è¡¨ï¼ˆproximal/distalï¼‰ï¼›è‹¥æ²’æœ‰ï¼Œæ”¹æŠ“ ASIA motor tableï¼ˆC5~T1ã€L2~S1ï¼‰ã€‚
    è¦å‰‡ï¼š**proximal å„ªå…ˆ**ã€è‹¥å¤šç­†å–**æœ€ä½**ï¼›proximal ç¼ºæ‰ç”¨ distalã€‚
      RUL/LUL â† ä¸Šè‚¢ï¼ˆprox: C5ã€C7ï¼›dist: C6ã€C8ã€T1ï¼‰
      RLL/LLL â† ä¸‹è‚¢ï¼ˆprox: L2ã€L3ï¼›dist: L4ã€L5ã€S1ï¼‰
    æ‰¾ä¸åˆ°å›å‚³ 'NA'
    """
    RUL = RLL = LUL = LLL = 'NA'
    if not pe_text:
        return {'RUL':RUL,'RLL':RLL,'LUL':LUL,'LLL':LLL}

    text = pe_text

    # ---------- A) å…ˆå˜—è©¦ M.P.(0-5) è¡¨ ----------
    m = re.search(r'M\.?P\.?\s*:\s*\(0-5\)(.*?)\n={3,}', text, flags=re.I|re.S)
    block = m.group(1) if m else None

    def collect_mp_tokens(src: str, limb: str, part: str, side: str) -> list[str]:
        toks = []
        pat = rf'{limb}\s+{part}\s+([0-5][+-]?|NT)\s+([0-5][+-]?|NT)'
        for mm in re.finditer(pat, src, flags=re.I):
            toks.append(mm.group(1 if side == 'R' else 2))
        return toks

    if block:
        r_ul = _pick_min_score_token(collect_mp_tokens(block, 'upper', 'proximal', 'R')) or \
               _pick_min_score_token(collect_mp_tokens(block, 'upper', 'distal',   'R'))
        l_ul = _pick_min_score_token(collect_mp_tokens(block, 'upper', 'proximal', 'L')) or \
               _pick_min_score_token(collect_mp_tokens(block, 'upper', 'distal',   'L'))
        r_ll = _pick_min_score_token(collect_mp_tokens(block, 'lower', 'proximal', 'R')) or \
               _pick_min_score_token(collect_mp_tokens(block, 'lower', 'distal',   'R'))
        l_ll = _pick_min_score_token(collect_mp_tokens(block, 'lower', 'proximal', 'L')) or \
               _pick_min_score_token(collect_mp_tokens(block, 'lower', 'distal',   'L'))

        if r_ul: RUL = r_ul
        if l_ul: LUL = l_ul
        if r_ll: RLL = r_ll
        if l_ll: LLL = l_ll
        return {'RUL':RUL,'RLL':RLL,'LUL':LUL,'LLL':LLL}

    # ---------- B) æ²’æœ‰ MP è¡¨ â†’ è§£æ ASIA motor table ----------
    # å…¸å‹æ ¼å¼ï¼š
    # Right               Left
    #   3-4  C5(...)      3-4
    #   2    C6(...)      2
    #   ...
    asia = {'R':{}, 'L':{}}

    def grab_row(level: str) -> tuple[str|None, str|None]:
        # å³å€¼åœ¨å·¦ï¼Œå·¦å€¼åœ¨å³
        pat = rf'^\s*([0-5][+-]?|[0-5]\s*-\s*[0-5])\s*{level}\b.*?([0-5][+-]?|[0-5]\s*-\s*[0-5])\s*$'
        m1 = re.search(pat, text, flags=re.I|re.M)
        if m1: return m1.group(1).strip(), m1.group(2).strip()
        # æŸäº›æª”æ¡ˆå¯èƒ½æŠŠå·¦/å³é¡›å€’æˆ–åŒåˆ—å¤šç©ºç™½ï¼Œåšå†ä¸€ç¨®å¯¬é¬†ç‰ˆ
        pat2 = rf'{level}\b.*?([0-5][+-]?|[0-5]\s*-\s*[0-5]).*?([0-5][+-]?|[0-5]\s*-\s*[0-5])'
        m2 = re.search(pat2, text, flags=re.I|re.S)
        if m2: return m2.group(1).strip(), m2.group(2).strip()
        return None, None

    for lv in ['C5','C6','C7','C8','T1','L2','L3','L4','L5','S1']:
        r, l = grab_row(lv)
        if r: asia['R'][lv] = r
        if l: asia['L'][lv] = l

    # ä¸Šè‚¢ï¼šproxï¼ˆC5ã€C7ï¼‰ï¼›distï¼ˆC6ã€C8ã€T1ï¼‰
    r_ul = _pick_min_score_token([asia['R'].get(x) for x in ['C5','C7'] if asia['R'].get(x)]) or \
           _pick_min_score_token([asia['R'].get(x) for x in ['C6','C8','T1'] if asia['R'].get(x)])
    l_ul = _pick_min_score_token([asia['L'].get(x) for x in ['C5','C7'] if asia['L'].get(x)]) or \
           _pick_min_score_token([asia['L'].get(x) for x in ['C6','C8','T1'] if asia['L'].get(x)])
    # ä¸‹è‚¢ï¼šproxï¼ˆL2ã€L3ï¼‰ï¼›distï¼ˆL4ã€L5ã€S1ï¼‰
    r_ll = _pick_min_score_token([asia['R'].get(x) for x in ['L2','L3'] if asia['R'].get(x)]) or \
           _pick_min_score_token([asia['R'].get(x) for x in ['L4','L5','S1'] if asia['R'].get(x)])
    l_ll = _pick_min_score_token([asia['L'].get(x) for x in ['L2','L3'] if asia['L'].get(x)]) or \
           _pick_min_score_token([asia['L'].get(x) for x in ['L4','L5','S1'] if asia['L'].get(x)])

    if r_ul: RUL = r_ul
    if l_ul: LUL = l_ul
    if r_ll: RLL = r_ll
    if l_ll: LLL = l_ll
    return {'RUL':RUL,'RLL':RLL,'LUL':LUL,'LLL':LLL}
def parse_mp_from_pe(pe_text: str) -> dict:
    """
    å…ˆå˜—è©¦å¾ MP è¡¨æŠ“ R/L çš„å¤šç­† MP å€¼ï¼›è‹¥æ²’æœ‰ï¼Œå°±å¾ ASIA motor tableï¼ˆC5~T1ã€L2~S1ï¼‰æŠ“ã€‚
    å›å‚³ {'R': å¹³å‡æ•¸å€¼, 'L': å¹³å‡æ•¸å€¼, 'all': å…©å´å¹³å‡}ï¼›æŠ“ä¸åˆ°å›å‚³ NaNã€‚
    """
    t = pe_text or ""
    vals_R, vals_L = [], []

    def _mp_to_float(mp_str: str) -> float:
        if not mp_str: return float('nan')
        s = mp_str.strip().upper()
        if s == 'NT': return float('nan')
        # '3-4' â†’ å– (3+4)/2? é€™è£¡æˆ‘å€‘è¦ã€Œä¿å®ˆã€ï¼Œç”¨è¼ƒä½ï¼š3
        nums = re.findall(r'[0-5]', s)
        if not nums: return float('nan')
        return float(min(int(n) for n in nums))

    # A) å…ˆæ‰¾ MP è¡¨
    r_pat = re.findall(r'\bR(?:ight)?[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?|[0-5]\s*-\s*[0-5])', t, flags=re.I)
    l_pat = re.findall(r'\bL(?:eft)?[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?|[0-5]\s*-\s*[0-5])',  t, flags=re.I)
    r2 = re.findall(r'MP\s*\(\s*R(?:ight)?\s*\)\s*[:ï¼š]?\s*([0-5][+-]?|[0-5]\s*-\s*[0-5])', t, flags=re.I)
    l2 = re.findall(r'MP\s*\(\s*L(?:eft)?\s*\)\s*[:ï¼š]?\s*([0-5][+-]?|[0-5]\s*-\s*[0-5])',  t, flags=re.I)
    parts = re.findall(r'\b(R|L)(?:UE|LE)\b[^:\n]{0,20}MP\s*[:ï¼š]?\s*([0-5][+-]?|[0-5]\s*-\s*[0-5])', t, flags=re.I)

    vals_R += [_mp_to_float(x) for x in r_pat+r2]
    vals_L += [_mp_to_float(x) for x in l_pat+l2]
    for side, mp in parts:
        (vals_R if side.upper()=='R' else vals_L).append(_mp_to_float(mp))

    # B) è‹¥ MP è¡¨æ²’æŠ“åˆ°ï¼Œæ”¹æŠ“ ASIA motor table
    if not vals_R and not vals_L:
        def pick(level: str) -> tuple[list[float], list[float]]:
            # åŒä¸€å±¤ç´šåªæœƒæœ‰ä¸€åˆ—ï¼ŒæŠ“å…©å´
            pat = rf'^\s*([0-5][+-]?|[0-5]\s*-\s*[0-5])\s*{level}\b.*?([0-5][+-]?|[0-5]\s*-\s*[0-5])\s*$'
            m = re.search(pat, t, flags=re.I|re.M)
            if not m:
                pat2 = rf'{level}\b.*?([0-5][+-]?|[0-5]\s*-\s*[0-5]).*?([0-5][+-]?|[0-5]\s*-\s*[0-5])'
                m = re.search(pat2, t, flags=re.I|re.S)
            if not m: return [], []
            return [_mp_to_float(m.group(1))], [_mp_to_float(m.group(2))]
        for lv in ['C5','C6','C7','C8','T1','L2','L3','L4','L5','S1']:
            r, l = pick(lv)
            vals_R += r
            vals_L += l

    def avg(lst):
        lst = [x for x in lst if x == x]  # drop NaN
        return sum(lst)/len(lst) if lst else float('nan')

    R = avg(vals_R)
    L = avg(vals_L)
    if (R==R) and (L==L): ALL = (R+L)/2
    elif (R==R): ALL = R
    elif (L==L): ALL = L
    else: ALL = float('nan')
    return {'R': R, 'L': L, 'all': ALL}



# ============== å‡ºé™¢ç›®æ¨™  ==============

def infer_discharge_goals_from_all(pe_text: str, ll_token: str | None) -> dict:
    """
    è¦å‰‡ï¼ˆé©ç”¨ CVA/SCI/TBI å…¨éƒ¨ï¼‰ï¼š
    1) è‹¥ Functional status çš„ transferã€sit up **éƒ½ Poor**ï¼ˆæˆ–å››å¤§é …çš† Poorï¼‰ï¼›
       **æˆ–** ä»»ä¸€ MMT/MP < 3  â†’ å‹¾ã€Œè‡ªè¡Œè½‰ä½ã€ã€Œåå§¿å¹³è¡¡ã€
    2) Gait/Walkerï¼š
       - æ˜ç¢ºå¯«å¯**ä¸éœ€ walker** è¡Œèµ° â†’ å‹¾ã€ŒæŒè¼”åŠ©å™¨ç¨ç«‹è¡Œèµ°ã€
       - æ˜ç¢ºå¯«**éœ€è¦ walker** è¡Œèµ° â†’ å‹¾ã€Œå”åŠ©æŒè¼”åŠ©å™¨è¡Œèµ°ã€
    3) è‹¥ Stand up é” **Fair ä»¥ä¸Š** â†’ å‹¾ã€Œè‡ªè¡Œæ“æ§è¼ªæ¤…æ´»å‹•ã€
    4) Brunnstrom ä¸‹è‚¢ï¼ˆLLï¼‰è‹¥å« V æˆ– VI â†’ å†åŠ å¼·ã€ŒæŒè¼”åŠ©å™¨ç¨ç«‹è¡Œèµ°ã€
    """
    goals = {
        "è‡ªè¡Œç¿»èº«": False, "åå§¿å¹³è¡¡": False, "è‡ªè¡Œè½‰ä½": False, "ç«™ç«‹": False,
        "è‡ªè¡Œæ“æ§è¼ªæ¤…æ´»å‹•": False, "å”åŠ©æŒè¼”åŠ©å™¨è¡Œèµ°": False, "æŒè¼”åŠ©å™¨ç¨ç«‹è¡Œèµ°": False,
    }

    txt = (pe_text or "").lower()
    comp = parse_functional_components(pe_text)

    # --- (1) è½‰ä½/åå§¿å¹³è¡¡æ¢ä»¶ ---
    four = [comp.get('rolling'), comp.get('sit_up'), comp.get('transfer'), comp.get('stand_up')]
    all_poor = all(v == 'poor' for v in four if v is not None) and len([v for v in four if v is not None]) >= 2

    # MP/MT (MMT) < 3 ?
    mp_all = parse_mp_from_pe(pe_text).get('all', float('inf'))
    mmt = parse_mmt_ul_ll_from_pe(pe_text)
    mmt_min = min(_token_min_value(mmt[k]) for k in ['RUL','RLL','LUL','LLL'] if k in mmt)

    if all_poor or (mp_all < 3) or (mmt_min < 3):
        goals["åå§¿å¹³è¡¡"] = True
        goals["è‡ªè¡Œè½‰ä½"] = True

    # è‹¥ rolling ä¹Ÿæ˜¯ poorï¼Œé™„å¸¶æŠŠã€Œè‡ªè¡Œç¿»èº«ã€ä¸€ä½µæ‹‰é€²ç›®æ¨™ï¼ˆå¸¸è¦‹æ—©æœŸç›®æ¨™ï¼‰
    if comp.get('rolling') == 'poor':
        goals["è‡ªè¡Œç¿»èº«"] = True

    # --- (2) Gait / Walker åˆ¤è®€ ---
    # ä¸éœ€ walkerï¼ˆç¨ç«‹è¡Œèµ°ï¼‰
    if re.search(r'\bfree\s*ambulation\b', txt) or \
       re.search(r'\bwalk(?:ing)?\s+(independent|independently|without\s+(a\s*)?(walker|aid|assistive\s*device))\b', txt):
        goals["æŒè¼”åŠ©å™¨ç¨ç«‹è¡Œèµ°"] = True
    # éœ€è¦ walkerï¼ˆå”åŠ©æŒè¼”å…·è¡Œèµ°ï¼‰
    if re.search(r'\bwalk(?:ing)?\s+(with|using)\s+(a\s*)?walker\b', txt) or \
       re.search(r'\bwalker\b', txt) and not goals["æŒè¼”åŠ©å™¨ç¨ç«‹è¡Œèµ°"]:
        goals["å”åŠ©æŒè¼”åŠ©å™¨è¡Œèµ°"] = True

    # --- (3) ç«™ç«‹åˆ° Fair ä»¥ä¸Š â†’ è¼ªæ¤…æ´»å‹•ï¼ˆè‡ªæ“æ§ï¼‰ ---
    if comp.get('stand_up') in ('fair', 'fair~good', 'good'):
        goals["è‡ªè¡Œæ“æ§è¼ªæ¤…æ´»å‹•"] = True
        goals["ç«™ç«‹"] = True

    # --- (4) Brunnstrom LL V/VI â†’ ç¨ç«‹æŒè¼”å…·è¡Œèµ° ---
    if ll_token:
        s = ll_token.upper().replace(' ', '')
        if any(p in ['V','VI'] for p in re.split(r'[-/]', s)):
            goals["æŒè¼”åŠ©å™¨ç¨ç«‹è¡Œèµ°"] = True

    return goals
# ===== è£œé½Šï¼šå‡ºé™¢ç›®æ¨™å€å¡Šçš„è¼¸å‡º =====
def build_discharge_goals(goals: dict) -> str:
    """æŠŠ infer_discharge_goals_from_all å›å‚³çš„å¸ƒæ— dict æ’ç‰ˆæˆå€å¡Šæ–‡å­—ã€‚"""
    def b(x): return 'â– ' if x else 'â–¡'
    order = ["è‡ªè¡Œç¿»èº«", "åå§¿å¹³è¡¡", "è‡ªè¡Œè½‰ä½", "ç«™ç«‹", "è‡ªè¡Œæ“æ§è¼ªæ¤…æ´»å‹•", "å”åŠ©æŒè¼”åŠ©å™¨è¡Œèµ°", "æŒè¼”åŠ©å™¨ç¨ç«‹è¡Œèµ°"]
    line = " ".join(f"{b(goals.get(k, False))}{k}" for k in order)
    return "ã€å‡ºé™¢ç›®æ¨™ã€‘\n" + line

# ============== è¨ˆç•«ä¿®æ­£èˆ‡åŠ å¼·ï¼ˆæ²¿ç”¨ä½ çš„è¦å‰‡ï¼‰ ==============
def build_plan_adjustment_from_assessment(diag: str, pe: str) -> str:
    expr, recep = infer_aphasia_types(diag, pe)
    is_global = expr and recep
    dysarthria, dysphagia_any, _, _ = infer_speech_swallow_trach(diag, pe)

    # ST å‹¾é¸
    st = {'å£è…”å‹•ä½œè¨“ç·´': False,'ç™¼éŸ³': False,'ååš¥èƒ½åŠ›': False,'èªè¨€ç†è§£': False,'èªè¨€è¡¨é”': False,'å£èªé•·åº¦': False}
    if dysphagia_any: st['å£è…”å‹•ä½œè¨“ç·´'] = st['ååš¥èƒ½åŠ›'] = True
    if expr or recep or is_global: st['ç™¼éŸ³'] = st['å£èªé•·åº¦'] = True
    if is_global:
        st['èªè¨€è¡¨é”'] = True; st['èªè¨€ç†è§£'] = True
    else:
        if expr:  st['èªè¨€è¡¨é”'] = True
        if recep: st['èªè¨€ç†è§£'] = True

    # è­·ç†ï¼ˆç®¡è·¯ï¼šçœ‹ Local findingï¼‰
    ng, foley, tr = parse_local_finding_tubes(pe)
    nursing_tube = (ng or foley or tr)
    tube_str = f"ï¼ˆ{ 'â– NG' if ng else 'â–¡NG' } { 'â– Foley' if foley else 'â–¡Foley' } { 'â– Tr.' if tr else 'â–¡Tr.' }ï¼‰"

    ptot = "PT&OT: " + " ".join([
        f"{box(False)}PROM", f"{box(True)}ç§»ä½è¨“ç·´", f"{box(True)}åå§¿å¹³è¡¡", f"{box(True)}è‚ŒåŠ›",
        f"{box(True)}ç«™ç«‹å¹³è¡¡", f"{box(True)}æŒæŒ‡åŠŸèƒ½", f"{box(True)}æ­¥æ…‹", f"{box(False)}è€åŠ›",
        f"{box(True)}æ—¥å¸¸ç”Ÿæ´»", f"{box(True)}å”èª¿", f"{box(False)}èªçŸ¥åŠŸèƒ½", f"{box(False)}é›»ç™‚", f"{box(False)}å…¶ä»–:____",
    ])
    st_line = "ST: " + " ".join([
        f"{box(st['å£è…”å‹•ä½œè¨“ç·´'])}å£è…”å‹•ä½œè¨“ç·´",
        f"{box(st['ç™¼éŸ³'])}ç™¼éŸ³",
        f"{box(st['ååš¥èƒ½åŠ›'])}ååš¥èƒ½åŠ›",
        f"{box(st['èªè¨€ç†è§£'])}èªè¨€ç†è§£",
        f"{box(st['èªè¨€è¡¨é”'])}èªè¨€è¡¨é”",
        f"{box(st['å£èªé•·åº¦'])}å£èªé•·åº¦",
    ])
    psy_line = "Psy: " + " ".join([
        f"{box(True)}èªçŸ¥åŠŸèƒ½", f"{box(True)}æ³¨æ„åŠ›", f"{box(False)}è¨˜æ†¶åŠ›",
        f"{box(False)}åŸ·è¡ŒåŠŸèƒ½", f"{box(False)}æƒ…ç·’æ§åˆ¶", f"{box(True)}å®¶å±¬è«®è©¢", f"{box(True)}ç–¾ç—…é©æ‡‰",
    ])
    nurse_line = "è­·ç†: " + " ".join([
        f"{box(True)}è‡ªæˆ‘ç…§é¡§èƒ½åŠ›",
        f"{box(nursing_tube)}ç®¡è·¯ç…§é¡§èˆ‡ç§»é™¤{tube_str}",
        f"{box(True)}è·Œå€’é é˜²",
        f"{box(False)}çš®è†š/å‚·å£ç…§é¡§",
        f"{box(False)}æ„ŸæŸ“é é˜²",
        f"{box(False)}å®‰ç½®",
    ])
    return "ã€æ²»ç™‚è¨ˆç•«ä¿®æ­£èˆ‡åŠ å¼·ã€‘\n" + "\n".join([ptot, st_line, psy_line, nurse_line, "å®¶å±¬:", "å…¨äºº:"])

# ============== è‡¨åºŠè©•ä¼°ï¼ˆä¾ç‰ˆæœ¬åˆ‡æ›å·®ç•°è¡Œï¼‰ ==============
def build_clinical_assessment_block(diagnosis_text: str, pe_text: str) -> str:
    case_type = detect_case_type(diagnosis_text)

    # å´åˆ¥ï¼ˆå„ªå…ˆåºï¼šMP > è¨ºæ–· > Brunnstrom ä¸»è© > å³ï¼‰â€” CVA ä»ç”¨æ–¼å·¦/å³ç„¡åŠ›æ‰“å‹¾
    side_mp = infer_hemiparesis_side_from_mp(pe_text)
    side_diag = infer_hemiparesis_side(diagnosis_text)
    side_pe, up, ud, ll = parse_brunnstrom_block(pe_text)
    side = (side_mp or side_diag or (side_pe.lower() if side_pe else None) or 'right')

    # èªè¨€/ååš¥/ç®¡è·¯
    expr, recep = infer_aphasia_types(diagnosis_text, pe_text)
    dysarthria, dysphagia_any, trach_plus, ng_plus = infer_speech_swallow_trach(diagnosis_text, pe_text)

    # ç§»å‹•æ–¹å¼ / ç§»ä½èƒ½åŠ› / èªçŸ¥
    mobility = infer_mobility_from_function(pe_text)
    transfer_ability = infer_transfer_from_function(pe_text)
    cog_level = infer_cognition_level(pe_text)

    # MAS é è¨­
    mas_R_el_wri_fin, mas_R_knee_ank, mas_L_el_wri_fin, mas_L_knee_ank = default_mas()

    # ååš¥éšœç¤™ï¼šNG(+)â†’åš´é‡ï¼›å¦å‰‡è‹¥æœ‰ dysphagia â†’ è¼•åº¦ï¼›å¦å‰‡ç„¡ï¼ˆåªå‹¾ä¸€å€‹ï¼‰
    swallow_none = swallow_mild = swallow_severe = False
    if ng_plus: swallow_severe = True
    elif dysphagia_any: swallow_mild = True
    else: swallow_none = True

    # èªè¨€éšœç¤™
    is_global = expr and recep

    lines = []
    lines.append('ã€è‡¨åºŠè©•ä¼°ã€‘')
    # ======= è‚¢é«”ç„¡åŠ›é¡å‹ï¼ˆä¾ã€Œè¨ºæ–·ã€æ±ºå®šï¼šå››è‚¢/é›™ä¸‹è‚¢/å–®å´ï¼‰ï¼‹ å´åˆ¥ï¼ˆå„ªå…ˆåºï¼šMP > Local finding > è¨ºæ–· > Brunnstrom > é è¨­å³ï¼‰ =======
    diag_low = safe_lower(diagnosis_text)
    has_quadri = any(w in diag_low for w in ["tetraplegia", "quadriplegia"])
    has_para  = "paraplegia" in diag_low
    has_hemi  = any(w in diag_low for w in ["hemiplegia", "hemiparesis"])

    # å´åˆ¥å„ªå…ˆåºï¼šMP > Local finding > diagnosis > Brunnstrom > é è¨­å³
    side_mp     = infer_hemiparesis_side_from_mp(pe_text)
    side_local  = infer_hemi_side_from_local(pe_text)
    side_diag   = infer_hemiparesis_side(diagnosis_text)
    side_pe, up, ud, ll = parse_brunnstrom_block(pe_text)
    side = (side_mp or side_local or side_diag or (side_pe.lower() if side_pe else None) or 'right')

    if has_quadri:
        limb_text = f"{box(False)}è‚¢é«”åç™± {box(False)}é›™ä¸‹è‚¢ç„¡åŠ› {box(True)}å››è‚¢ç„¡åŠ› {box(False)}å·¦å´ç„¡åŠ› {box(False)}å³å´ç„¡åŠ›"
    elif has_para:
        limb_text = f"{box(False)}è‚¢é«”åç™± {box(True)}é›™ä¸‹è‚¢ç„¡åŠ› {box(False)}å››è‚¢ç„¡åŠ› {box(False)}å·¦å´ç„¡åŠ› {box(False)}å³å´ç„¡åŠ›"
    elif has_hemi:
        limb_text = f"{box(True)}è‚¢é«”åç™± {box(False)}é›™ä¸‹è‚¢ç„¡åŠ› {box(False)}å››è‚¢ç„¡åŠ› {box(side=='left')}å·¦å´ç„¡åŠ› {box(side=='right')}å³å´ç„¡åŠ›"
    else:
        # è‹¥è¨ºæ–·æ²’æœ‰æ˜ç¢ºä¸‰é¡é—œéµå­—ï¼Œfallback ç¶­æŒåŸæœ¬é¡¯ç¤ºé‚è¼¯ï¼ˆä»¥æ¨è«–å´åˆ¥é¡¯ç¤ºå–®å´ï¼‰
        limb_text = f"{box(True)}è‚¢é«”åç™± {box(False)}é›™ä¸‹è‚¢ç„¡åŠ› {box(False)}å››è‚¢ç„¡åŠ› {box(side=='left')}å·¦å´ç„¡åŠ› {box(side=='right')}å³å´ç„¡åŠ›"

    lines.append(limb_text)

    lines.append('ç§»å‹•æ–¹å¼ ' + ' '.join([
        f"{box(mobility=='Bed ridden')}Bed ridden",
        f"{box(mobility=='W/C care')}W/C care",
        f"{box(mobility=='W/C activity')}W/C activity",
        f"{box(mobility=='walker')}walker",
        f"{box(mobility=='Free ambulation')}Free ambulation",
    ]))
    lines.append('ç§»ä½èƒ½åŠ› ' + ' '.join([
        f"{box(transfer_ability=='Good')}Good",
        f"{box(transfer_ability=='Fair~good')}Fair~good",
        f"{box(transfer_ability=='Fair')}Fair",
        f"{box(transfer_ability=='Poor~fair')}Poor~fair",
        f"{box(transfer_ability=='Poor')}Poor",
    ]))

    # ç‰ˆæœ¬å·®ç•°è¡Œï¼š
    if case_type == 'CVA':
        side_cap = 'Right' if str(side).startswith('r') else 'Left'
        lines.append(f'Brunnstrom stage: {side_cap}   up / ud / ll: {up} / {ud} / {ll}')
    elif case_type == 'SCI':
        mmt = parse_mmt_ul_ll_from_pe(pe_text)
        lines.append(f"MMT: RUL/RLL: {mmt['RUL']} / {mmt['RLL']}   LUL/LLL: {mmt['LUL']} / {mmt['LLL']}")
        barthel = extract_barthel_block(pe_text)
        if barthel:
            lines.append(barthel)
    elif case_type == 'TBI':
        barthel = extract_barthel_block(pe_text)
        if barthel:
            lines.append(barthel)

    # å…¶é¤˜ç›¸åŒ
    lines.append('ç—™æ”£spasticity: Right (elbow/wrist/finger, knee/ankle):' f'{mas_R_el_wri_fin},{mas_R_knee_ank}')
    lines.append('              (MAS)Left (elbow/wrist/finger, knee/ankle):' f'{mas_L_el_wri_fin},{mas_L_knee_ank}')
    lines.append("ååš¥éšœç¤™ " + ' '.join([
        f"{box(swallow_none)}ç„¡",
        f"{box(swallow_mild)}è¼•åº¦ã€éœ€ç›£è¦–",
        f"{box(swallow_severe)}åš´é‡ã€éœ€é¼»èƒƒç®¡",
    ]))
    lines.append("èªè¨€éšœç¤™ " + ' '.join([
        f"{box(not (expr or recep or dysarthria or trach_plus))}ç„¡",
        f"{box(expr and not is_global)}è¡¨é”æ€§å¤±èªç—‡",
        f"{box(recep and not is_global)}æ¥å—æ€§å¤±èªç—‡",
        f"{box(is_global)}çƒæ€§å¤±èªç—‡",
        f"{box(dysarthria)}æ§‹éŸ³ç•°å¸¸",
        f"{box(trach_plus)}æ°£åˆ‡",
    ]))
    lines.append(f"èªçŸ¥éšœç¤™ {box(cog_level=='å·®')}å·® {box(cog_level=='å°šå¯')}å°šå¯ {box(cog_level=='è‰¯')}è‰¯")
    lines.append(f"é—œç¯€æ”£ç¸® {box(True)}ç„¡ {box(False)}æœ‰ã€éƒ¨ä½________________")
    return '\n'.join(lines)

# ============== å‡ºé™¢ç›®æ¨™å€å¡Š & å ±å‘Šå°è£ ==============
def build_discharge_goals_block(pe_text: str) -> str:
    _, _, _, ll = parse_brunnstrom_block(pe_text)
    goals = infer_discharge_goals_from_all(pe_text, ll)
    return build_discharge_goals(goals)

def generate_report(diagnosis_text: str, pe_text: str, html_text: str) -> str:
    assessment = build_clinical_assessment_block(diagnosis_text, pe_text)
    flags = parse_treatments_from_html(html_text)
    flags = apply_st_from_assessment(flags, diagnosis_text, pe_text)
    treatment = build_treatment_block(flags)
    goals = build_discharge_goals_block(pe_text)
    adjust = build_plan_adjustment_from_assessment(diagnosis_text, pe_text)
    return "\n\n".join([assessment, treatment, goals, adjust])


import streamlit as st

st.title("ğŸ¥ å¾©å¥ç§‘ Grandrun å ±å‘Šç”¢ç”Ÿå™¨")

diagnosis_text = st.text_area("è¨ºæ–· (Diagnosis)", height=150)
pe_text = st.text_area("PE / Functional status / Local finding", height=300)
html_text = st.text_area("HTML (æ²»ç™‚é†«å›‘)", height=200)

if st.button("ç”¢ç”Ÿå ±å‘Š"):
    if not diagnosis_text.strip() and not pe_text.strip():
        st.warning("è«‹è‡³å°‘è¼¸å…¥ Diagnosis æˆ– PE")
    else:
        report = generate_report(diagnosis_text, pe_text, html_text)
        st.success("âœ… å·²ç”¢ç”Ÿå ±å‘Š")
        st.text_area("å ±å‘Šå…§å®¹", report, height=600)